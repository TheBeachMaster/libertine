set -o errexit +o hashall

function doDownloads()
{
	# Download certificate authorities in parallel
	prepareWaitForJobs
	local certificateAuthorityName
	for certificateAuthorityName in "${!certificateAuthorities_Mirror[@]}"
	do
		parallelJob downloadFileAndCheckHash "certificate authority" "${certificateAuthorities_Mirror["${certificateAuthorityName}"]}" "${certificateAuthorities_RelativePath["${certificateAuthorityName}"]}" "$certificateAuthoritiesPath" "${certificateAuthorities_FileName["${certificateAuthorityName}"]}" "${certificateAuthorities_Compression["${certificateAuthorityName}"]}" "${certificateAuthorities_Post["${certificateAuthorityName}"]}" "${certificateAuthorities_ReferFrom["${certificateAuthorityName}"]}" "no" "${certificateAuthorities_Hashes["${certificateAuthorityName}"]}"
	done
	waitForJobs
	
	# Download signatures, keyrings and keys in parallel
	prepareWaitForJobs
	local -i index
	for index in ${!signatures_Mirror[@]}
	do
		parallelJob "signature" "${signatures_Mirror[$index]}" "${signatures_RelativePath[$index]}" "$signaturesPath" "${signatures_FileName[$index]}" "${signatures_Compression[$index]}" "${signatures_Post[$index]}" "${signatures_ReferFrom[$index]}" "yes" ""
	done
	local -i index
	for index in ${!keyrings_Mirror[@]}
	do
		parallelJob downloadFileAndCheckHash "keyring" "${keyrings_Mirror[$index]}" "${keyrings_RelativePath[$index]}" "$keyringsPath" "${keyrings_FileName[$index]}" "${keyrings_Compression[$index]}" "${keyrings_Post[$index]}" "${keyrings_ReferFrom[$index]}" "no" "${keyrings_Hashes[$index]}"
	done
	local -i index
	for index in ${!keys_Mirror[@]}
	do
		parallelJob downloadFileAndCheckHash "key" "${keys_Mirror[$index]}" "${keys_RelativePath[$index]}" "$keysPath" "${keys_FileName[$index]}" "${keys_Compression[$index]}" "${keys_Post[$index]}" "${keys_ReferFrom[$index]}" "yes" "${keys_Hashes[$index]}"
	done
	waitForJobs
	
	# Download packages and patches in parallel
	prepareWaitForJobs
	local -i index
	for index in ${!sourcePackages_Mirror[@]}
	do
		parallelJob downloadFileAndCheckHash "source package" "${sourcePackages_Mirror[$index]}" "${sourcePackages_RelativePath[$index]}" "/dev/null" "${sourcePackages_FileName[$index]}" "${sourcePackages_Compression[$index]}" "${sourcePackages_Post[$index]}" "${sourcePackages_ReferFrom[$index]}" "no" "${sourcePackages_Hashes[$index]}"
	done
	local -i index
	for index in ${!patches_Mirror[@]}
	do
		parallelJob downloadFileAndCheckHash "patch" "${patches_Mirror[$index]}" "${patches_RelativePath[$index]}" "/dev/null" "${patches_FileName[$index]}" "${patches_Compression[$index]}" "${patches_Post[$index]}" "${patches_ReferFrom[$index]}" "no" "${patches_Hashes[$index]}"
	done
	waitForJobs
}

function linkOrCopyFile()
{
	local -r mirrorName="$1"
	local -r relativePath="$2"
	local -r toPath="$3"
	local -r fileName="$4"
	
	if [ "$toPath" = "/dev/null" ]; then
		return
	fi
	
	local -r downloadFilePath="$lfsDownloadsPath"/"$mirrorName"/"$relativePath"
	local -r linkTo="$toPath"/"$fileName"
	
	if [ ! -f "$linkTo" ]; then
		rm -rf -- "$linkTo"
		# Try to hard link, then copy
		ln --force "$downloadFilePath" "$linkTo" 2>/dev/null || cp --force "$downloadFilePath" "$linkTo"
	fi
}

# metalink in the latest curl (7.29.0) and wget (1.15, not released) allows parallel downloading and fail-over and obsoletes mirrorNames logic
function downloadFileAndCheckHash()
{
	if [ $# -ne 10 ]; then
		exitError "Needs 10 arguments"
	fi
	
	local -r downloadName="$1"
	local -r mirrorName="$2"
	local -r relativePath="$3"
	local -r toPath="$4"
	local -r fileName="$5"
	local -r decompressionOption="$6"
	local -r postData="$7"
	local -r referFrom="$8"
	local -r hashesMayBeEmpty="$9"
	shift 9
	local -r hashes="$1"
	
	local -r url="${mirrors_Url["${mirrorName}"]}${relativePath}"
	local -i exitCode
	
	mkdir -m 0755 -p "$downloadsLogsPath"
	
	local -r downloadFilePath="$lfsDownloadsPath"/"$mirrorName"/"$relativePath"
	local -r downloadFileName="$(purebash_basename "$downloadFilePath")"
	local -r downloadFolderPath="$(purebash_dirname "$downloadFilePath")"
	if [ ! -d "$downloadFolderPath" ]; then
		rm -rf -- "$downloadFolderPath"
	fi
	mkdir -m 0755 -p "$downloadFolderPath"
	
	# Extracts file path - currently only used by linux package / HKP_UNCOMPRESSED
	local -r extractsFilePath="$lfsExtractsPath"/"$mirrorName"/"$relativePath".decompressed
	local -r extractsFolderPath="$(purebash_dirname "$extractsFilePath")"

	SECONDS=0
	if [ -f "$extractsFilePath" ]; then
		informationMessage TASK "Using cached extracted $downloadName $url at $extractsFilePath"
		informationMessage PASS "Using cached extracted $downloadName $url at $extractsFilePath ($SECONDS seconds)"
	elif [ -f "$downloadFilePath" ]; then
		informationMessage TASK "Copying from cache $downloadName $url at $extractsFilePath"
		rm -rf -- "$extractsFilePath"
		linkOrCopyFile "$mirrorName" "$relativePath" "$toPath" "$fileName"
		
		informationMessage PASS "Copying from cache $downloadName $url at $extractsFilePath ($SECONDS seconds)"
	else
		informationMessage TASK "Downloading $downloadName $url to $mirrorName/$relativePath"
		
		rm -rf -- "$downloadFilePath"
		rm -rf -- "$extractsFilePath"
		
		# We re-load the config after specifying our options
		touch "$HOME"/.curlrc
		
		# Only enabled compression for uncompressed files, because a few badly configured servers (eg http://www.multiprecision.org/mpc/download/mpc-1.0.1.tar.gz) then stream the non-gz tarball
		if [ -z "$decompressionOption" ]; then
			local -r curlCompressionOption="--compressed "
		else
			local -r curlCompressionOption=""
		fi
		
		local certificateAuthorityName="${mirrors_CertificateAuthority["${mirrorName}"]}"
		if [ -z "$certificateAuthorityName" ]; then
			# Unless ssl hashing has occurred, capath will not reference any certificate authorities
			local -ar certificateAuthorityOption=("--insecure" "--capath" "$certificateAuthoritiesPath")
		else
			if [ "${certificateAuthorities_Parent["${certificateAuthorityName}"]}" = "root" ]; then
				if [ "${certificateAuthorities_Format["${certificateAuthorityName}"]}" == "PEM" ]; then
					local -r certificateAuthorityBundle="$certificateAuthoritiesPath"/"${certificateAuthorities_FileName["${certificateAuthorityName}"]}"
				else
					# Assume DER, other formats are much rarer
					temporaryFileToRemoveOnExit
					local -r certificateAuthorityBundle="$TMP_FILE"
					openssl x509 -in "$certificateAuthoritiesPath"/"${certificateAuthorities_FileName["${certificateAuthorityName}"]}" -inform DER -outform PEM >"$certificateAuthorityBundle"
				fi
				local -r certType="${certificateAuthorities_Format["${certificateAuthorityName}"]}"
			else
				temporaryFileToRemoveOnExit
				local -r certificateAuthorityBundle="$TMP_FILE"
				
				while [ "$certificateAuthorityName" != "root" ]
				do
					if [ "${certificateAuthorities_Format["${certificateAuthorityName}"]}" == "PEM" ]; then
						cat "$certificateAuthoritiesPath"/"${certificateAuthorities_FileName["${certificateAuthorityName}"]}" >>"$certificateAuthorityBundle"
					else
						# Assume DER, other formats are much rarer
						openssl x509 -in "$certificateAuthoritiesPath"/"${certificateAuthorities_FileName["${certificateAuthorityName}"]}" -inform DER -outform PEM >>"$certificateAuthorityBundle"
					fi
					certificateAuthorityName="${certificateAuthorities_Parent["${certificateAuthorityName}"]}"
				done
				local -r certType=PEM
			fi
			local -ar certificateAuthorityOption=("--capath" "$certificateAuthoritiesPath" "--cacert" "$certificateAuthorityBundle" "--cert-type" "$certType")
		fi
		
		if [ -z "$postData" ]; then
			local -ar postOption=("--get")
		else
			local -ar postOption=("--data-ascii" "$postData")
		fi
		
		if [ -z "$referFrom" ]; then
			local -r referer="$(dirname "$url")/"
		else
			local -r referer="$referFrom"
		fi
		local -ar referFromOption=("--referer" "${referer};auto")
		
		set +e
		curl --fail --silent --show-error \
		"${postOption[@]}" \
		"${referFromOption[@]}" \
		--user-agent "lfs/${LFS_DISTRIBUTION_VERSION}" \
		--location --max-redirs 5 --retry 20 \
		--anyauth --netrc-optional --tlsv1 "${certificateAuthorityOption[@]}" \
		${curlCompressionOption}--remote-time \
		--dump-header "$downloadsLogsPath"/"$fileName".headers.log \
		--trace-time --trace-ascii "$downloadsLogsPath"/"$fileName".trace-ascii.log \
		--stderr "$downloadsLogsPath"/"$fileName".stderr.log \
		--write-out '%{url_effective}\t%{http_code}\t%{ssl_verify_result}\t%{http_connect}\t%{time_total}\t%{size_download}\t%{speed_download}\t%{num_redirects}\n' \
		--config "$HOME"/.curlrc \
		--url "$url" --output "$downloadFilePath" \
		1>"$downloadsLogsPath"/"$fileName".stdout.log
		exitCode=$?
		set -e
		if [ $exitCode -ne 0 ]; then
			informationMessage FAIL "Downloading $downloadName $url to $mirrorName/$relativePath (logs: $downloadsLogsPath/$fileName.*.log)"
		else
			linkOrCopyFile "$mirrorName" "$relativePath" "$toPath" "$fileName"
			informationMessage PASS "Downloading $downloadName $url to $mirrorName/$relativePath ($SECONDS seconds)"
		fi
	fi
	
	if [ "$hashesMayBeEmpty" = "yes" ]; then
		if [ ${#hashes} -eq 0 ]; then
			return 0
		fi
	fi
	
	if [ "$skipSignatureChecks" = "yes" ]; then
		return 0
	fi
	
	SECONDS=0
	informationMessage TASK "Verifying $downloadName $url hashes of $downloadFilePath"
	
	local hashNameAndValue
	local hashName
	local hashValue
	local hashSignatureFileName
	local hashProgram
	local -i hasHash=1
	local progressMessage
	local signatureFileName
	local temporaryFolder
	for hashNameAndValue in ${hashes}
	do
		IFS=':' read -r -d$'\n' hashName hashValue hashSignatureFileName <<<"$hashNameAndValue"
		case "$hashName" in
			
			NO_DIGESTS_BECAUSE_VALUE_IS_UNIQUE_PER_DOWNLOAD)
				hasHash=0
			;;
			
			SIZE)
				hasHash=0
				if ! verifySize "$downloadFolderPath" "$downloadFileName" "$hashValue"; then
					informationMessage FAIL "Verifying $downloadName $url size of $downloadFilePath ($progressMessage)"
				fi
			;;
			
			MD5|SHA1|SHA224|SHA256|SHA384|SHA512)
				hashProgram=${hashName,,}sum
				hasHash=0
				if ! verifyHash "$downloadFolderPath" "$downloadFileName" "$hashProgram" "$hashValue"; then
					informationMessage FAIL "Verifying $downloadName $url hashes of $downloadFilePath $hashName hash sum of $downloadName does not match, check logs $downloadsLogsPath/$fileName.$hashProgram.log)"
					exit 1
				fi
			;;
			
			KEYRING|KEYFILE|HKP|HKP_UNCOMPRESSED)
				hasHash=0
				progressMessage="$hashName signature does not match, check logs $downloadsLogsPath/$fileName.${hashName,,}.log"
				if [ -z "$hashSignatureFileName" ]; then
					signatureFileName="$fileName".sig
				else
					signatureFileName="$hashSignatureFileName"
				fi
				
				case "$hashName" in
					KEYRING)
						if ! verifyKeyringSignature "$downloadFolderPath" "$downloadFileName" "$hashValue" "$signatureFileName" "no"; then
							informationMessage FAIL "Verifying $downloadName $url signature of $downloadFilePath ($progressMessage)"
							exit 1
						fi
					;;
			
					KEYFILE)
						if ! verifyKeyFileSignature "$downloadFolderPath" "$downloadFileName" "$hashValue" "$signatureFileName" "no"; then
							informationMessage FAIL "Verifying $downloadName $url signature of $downloadFilePath ($progressMessage)"
							exit 1
						fi
					;;
			
					HKP)
						if ! verifyHkpSignature "$downloadFolderPath" "$downloadFileName" "$hashValue" "$signatureFileName" "no"; then
							informationMessage FAIL "Verifying $downloadName $url signature of $downloadFilePath ($progressMessage)"
							exit 1
						fi
					;;
			
					HKP_UNCOMPRESSED)
						if [ ! -f "$extractsFilePath" ]; then
							if [ ! -d "$extractsFolderPath" ]; then
								rm -rf -- "$extractsFolderPath"
							fi
							mkdir -m 0755 -p "$extractsFolderPath"
							rm -rf -- "$extractsFilePath"
							extractFileForSignatureTest "$decompressionOption" "$downloadFilePath" >"$extractsFilePath"
						fi
						
						if ! verifyHkpSignature "$extractsFolderPath" "$(purebash_basename "$extractsFilePath")" "$hashValue" "$signatureFileName" "yes"; then
							informationMessage FAIL "Verifying $downloadName $url signature of $downloadFilePath ($progressMessage)"
							exit 1
						fi
					;;
				esac
				
			;;
			
			
			*)
				informationMessage FAIL "Verifying $downloadName $url hashes of $downloadFilePath (Unsupported hash algorithm $hashName for $toPath/$fileName)"
				exit 1
			;;
			
		esac
	done
	
	if [ $hasHash -ne 0 ]; then
		informationMessage FAIL "Verifying $downloadName $url hashes of $downloadFilePath (no hash algorithms specified)"
		exit 1
	fi

	informationMessage PASS "Verifying $downloadName $url hashes of $downloadFilePath ($SECONDS seconds)"
}

function gpgVerifySignatureUsingKey()
{
	local -r toPath="$1"
	local -r fileName="$2"
	local -r keyFileOrKeyringFilePath="$3"
	local -r signatureFileName="$4"
	local -r isCompressed="$5"
	local -r method="$6"
	
	if [ ! -f "$keyFileOrKeyringFilePath" ]; then
		exitError "$keyFileOrKeyringFilePath does not exist"
	fi
	
	if [ "$isCompressed" = "no" ]; then
		local -r logFileName="$downloadsLogsPath"/"$fileName"."$method".log
	else
		local -r logFileName="$downloadsLogsPath"/"$fileName"."$method"_uncompressed.log
	fi
	
	if [ "$method" != "keyring" ]; then
		
		temporaryFileToRemoveOnExit
		local -r publicKeyring="$TMP_FILE"
		# GPG is badly behaved, and creates a back up file we'll need to remove
		addFileToRemoveOnExit "$publicKeyring"~
		
		temporaryFileToRemoveOnExit
		local -r trustDb="$TMP_FILE"
		cat "$gpghomePath"/trustdb.gpg >>"$trustDb"
		
		# gpg mucks with its trustdb when importing, which is a nuisance
		gpg --no-options --no-greeting --no-permission-warning --no-auto-check-trustdb --no-secmem-warning \
		--no-random-seed-file --ignore-time-conflict \
		--no-verbose --quiet --batch --no-tty --exit-on-status-write-error \
		--lock-never --no-auto-check-trustdb --no-sig-cache \
		--homedir "$gpghomePath" --trustdb-name "$trustDb" \
		--no-default-keyring --secret-keyring secring.gpg \
		--primary-keyring "$publicKeyring" --keyring "$publicKeyring" \
		--import "$keyFileOrKeyringFilePath" </dev/null 1>"$logFileName" 2>&1
		
		local -ir exitCode=$?
		if [ $exitCode -ne 0 ]; then
			return $exitCode
		fi
		
	else
		local -r publicKeyring="$keyFileOrKeyringFilePath"
		local -r trustDb="trustdb.gpg"
	fi
	
	gpg --no-options --no-greeting --no-permission-warning --no-auto-check-trustdb --no-secmem-warning \
	--no-random-seed-file --ignore-time-conflict \
	--no-verbose --quiet --batch --no-tty --exit-on-status-write-error \
	--lock-never --no-auto-check-trustdb --no-sig-cache \
	--homedir "$gpghomePath" --trustdb-name "$trustDb" \
	--no-default-keyring --secret-keyring secring.gpg \
	--primary-keyring "$publicKeyring" --keyring "$publicKeyring" \
	--verify "$signaturesPath"/"$signatureFileName" "$toPath"/"$fileName" </dev/null 1>>"$logFileName" 2>&1
	
	return $?
}

function verifySize()
{
	local -r toPath="$1"
	local -r fileName="$2"
	local -ir expectedSize=$3
	
	local -i exitCode
	local -r logFile="$downloadsLogsPath"/"$fileName".size.log
	pushd "$toPath">/dev/null
	
		local -ir actualSize=$(stat -c '%s' "$fileName")
		if [ $actualSize -ne $expectedSize ]; then
			exitCode=1
		else
			exitCode=0
		fi
		
	popd >/dev/null
	
	return $exitCode
}

function verifyHash()
{
	local -r toPath="$1"
	local -r fileName="$2"
	local -r hashProgram="$3"
	local -r hashValue="$4"
	
	local -r logFile="$downloadsLogsPath"/"$fileName".$hashProgram.log
	pushd "$toPath">/dev/null
		$hashProgram -c -w <<<"${hashValue}  ${fileName}" 1>"$logFile" 2>&1
		local -ir exitCode=$?
	popd >/dev/null
	
	return $exitCode
}

function verifyKeyringSignature()
{
	local -r toPath="$1"
	local -r fileName="$2"
	local -r keyring="$3"
	local -r signatureFileName="$4"
	local -r isCompressed="$5"
	
	case "$keyring" in
		
		secring.gpg|trustdb.gpg)
			exitError "The keyring $keyring is not a public keyring"
		;;
		
	esac
	
	if [ "${keyring##*.}" != "gpg" ]; then
		exitError "Keyrings must be gpg - $keyring is not"
	fi
	
	gpgVerifySignatureUsingKey "$1" "$2" "$keyringsPath"/"$keyring" "$4" "$5" "keyring"
}

function verifyKeyFileSignature()
{
	gpgVerifySignatureUsingKey "$1" "$2" "$keysPath"/"$3" "$4" "$5" "key"
}

function verifyHkpSignature()
{
	gpgVerifySignatureUsingKey "$1" "$2" "$keysPath"/"$3" "$4" "$5" "hkp"
}

function extractFileForSignatureTest()
{
	local -r decompressionOption="$1"
	local -r fileToDecompress="$2"
	if [ "$decompressionOption" = "" ]; then
		cat $fileToDecompress
	fi
	
	case "$decompressionOption" in
		gzip|compress)
			gzip --decompress --stdout --no-name --quiet -- "$fileToDecompress"
		;;
		
		bzip2)
			bzip2 --decompress --stdout --quiet -- "$fileToDecompress"
		;;
		
		lzop)
			lzop --decompress --stdout --no-name --quiet -- "$fileToDecompress"
		;;
		
		lzip)
			lzip --decompress --quiet --stdout -- "$fileToDecompress"
		;;
		
		lzma)
			xz --format=lzma --decompress --stdout -- "$fileToDecompress"
		;;
		
		xz)
			xz --decompress --stdout --quiet --quiet -- "$fileToDecompress"
		;;
		
		*)
			exitError "Unknown compression option $decompressionOption"
		;;
	esac
}

function tarExtract()
{
	local -r sourcePackageName="$1"
	local -r tarball="$2"
	local -r tarballFolder="$3"
	local -r tarballCompression="$4"
	local -r isTarbomb="$5"
	
	SECONDS=0
	informationMessage TASK "Extracting $LFS_PHASE dependency $LFS_DEPENDENCY_NAME version $LFS_DEPENDENCY_VERSION tarball $tarball"
	
	pushd "$(purebash_dirname "$tarball")" >/dev/null
		
		# This slightly odd code is to overcome a problem on Mac OS X where tarballs contain ; and = (when downloaded from GNU's Savannah, eg config.git;h=23424234234 )
		#local -r absoluteTarballPath="$(pwd)"/"$(purebash_basename "$tarball")"
		ln -s "$(purebash_basename "$tarball")" temporary-tarball-name-to-fix-a-bug-in-mac-os-x-not-liking-semicolon-and-equals-in-filename-for-tar
		local -r absoluteTarballPath="$(pwd)"/temporary-tarball-name-to-fix-a-bug-in-mac-os-x-not-liking-semicolon-and-equals-in-filename-for-tar
		
	popd >/dev/null
	
	if [ "$isTarbomb" = "file" ]; then
		if [ -z "$tarballFolder" ]; then
			exitError "Empty tarballFolder is not supported"
		fi
		
		if [ $UID -eq $LFS_DEPENDENCY_UID ]; then
			mkdir -m 0755 -p "$tarballFolder"
			if [ -z "$tarballCompression" ]; then
				mv "$tarball" "$tarballFolder"
			else
				${tarballCompression} -d -c "$tarball" >"$tarballFolder"/file
			fi
		else
			
			mkdir -m 0755 -p "$tarballFolder"
			chown ${LFS_DEPENDENCY_UID}:${LFS_DEPENDENCY_GID} "$tarballFolder"
			if [ -z "$tarballCompression" ]; then
				sudo -u \#${LFS_DEPENDENCY_UID} -g \#${LFS_DEPENDENCY_GID} -s mv "$tarball" "$tarballFolder"
			else
				# Using sudo ensures that there is never a chance the file exists as root
				sudo -u \#${LFS_DEPENDENCY_UID} -g \#${LFS_DEPENDENCY_GID} -s ${tarballCompression} -d -c "$tarball" >"$tarballFolder"/file
			fi
		fi
		
		rm -rf "$absoluteTarballPath"
		
		informationMessage PASS "Extracting $LFS_PHASE dependency $LFS_DEPENDENCY_NAME version $LFS_DEPENDENCY_VERSION tarball $tarball ($SECONDS seconds)"
		
		return 0
	fi
	
	if [ "$isTarbomb" = "tarbomb" ]; then
		if [ $UID -eq $LFS_DEPENDENCY_UID ]; then
			mkdir -m 0755 -p "$tarballFolder"
		else	
			mkdir -m 0755 -p "$tarballFolder"
			chown ${LFS_DEPENDENCY_UID}:${LFS_DEPENDENCY_GID} "$tarballFolder"
		fi
		pushd "$tarballFolder" >/dev/null
	fi
		
		if [ -z "$tarballCompression" ]; then
			local -r compressionOption=""
		else
			local -r compressionOption=" --$tarballCompression"
		fi
		
		if [ $UID -eq $LFS_DEPENDENCY_UID ]; then
			tar --extract --numeric-owner --preserve-permissions --no-same-owner${compressionOption} --file "$absoluteTarballPath"
		else
			# Using sudo ensures that there is never a chance the extracted tar ball exists as root
			sudo -u \#${LFS_DEPENDENCY_UID} -g \#${LFS_DEPENDENCY_GID} -s tar --extract --numeric-owner --preserve-permissions --no-same-owner${compressionOption} --file "$absoluteTarballPath"
		fi
	
	if [ "$isTarbomb" = "tarbomb" ]; then
		popd >/dev/null
	fi
	
	if [ ! -e "$sourcePackageName" ]; then
		ln -s "$tarballFolder" "$sourcePackageName"
	fi
	
	rm -rf "$absoluteTarballPath"
	
	informationMessage PASS "Extracting $LFS_PHASE dependency $LFS_DEPENDENCY_NAME version $LFS_DEPENDENCY_VERSION tarball $tarball ($SECONDS seconds)"
}
